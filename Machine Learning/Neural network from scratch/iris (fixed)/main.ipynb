{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self,nodei,nodeh,nodeo,a,traindata,testdata,biasw1,biasw2,errort):\n",
    "        self.nodeh = nodeh #number of hidden nodes\n",
    "        self.nodei = nodei #number of input nodes\n",
    "        self.nodeo = nodeo #number of output nodes\n",
    "        self.errort = errort #tolerable error\n",
    "        self.biasw1= np.full((1, self.nodeh), biasw1)\n",
    "        self.w1 = np.vstack([np.random.rand(self.nodei,self.nodeh),self.biasw1])\n",
    "        self.biasw2= np.full((1, self.nodeo), biasw2)\n",
    "        self.w2 = np.vstack([np.random.rand(self.nodeh,self.nodeo),self.biasw2])\n",
    "        self.a = a\n",
    "        traindat = pd.read_csv(traindata, header=None)\n",
    "        testdat = pd.read_csv(testdata, header=None)\n",
    "        traindat.columns = ['0','1','2','3','4']\n",
    "        testdat.columns = ['0','1','2','3','4']\n",
    "        self.maxtrain = traindat.max(axis=0)\n",
    "        self.mintrain = traindat.min(axis=0)\n",
    "        self.maxtest = traindat.max(axis=0)\n",
    "        self.mintest = traindat.min(axis=0)\n",
    "        \n",
    "        #NORMALIZATION MIN-MAX\n",
    "        traindat['0']=traindat['0'].apply(lambda x: (x-self.mintrain[0])/(self.maxtrain[0]-self.mintrain[0]))\n",
    "        traindat['1']=traindat['1'].apply(lambda x: (x-self.mintrain[1])/(self.maxtrain[1]-self.mintrain[1]))\n",
    "        traindat['2']=traindat['2'].apply(lambda x: (x-self.mintrain[2])/(self.maxtrain[2]-self.mintrain[2]))\n",
    "        traindat['3']=traindat['3'].apply(lambda x: (x-self.mintrain[3])/(self.maxtrain[3]-self.mintrain[3]))\n",
    "        testdat['0']=testdat['0'].apply(lambda x: (x-self.mintest[0])/(self.maxtest[0]-self.mintest[0]))\n",
    "        testdat['1']=testdat['1'].apply(lambda x: (x-self.mintest[1])/(self.maxtest[1]-self.mintest[1]))\n",
    "        testdat['2']=testdat['2'].apply(lambda x: (x-self.mintest[2])/(self.maxtest[2]-self.mintest[2]))\n",
    "        testdat['3']=testdat['3'].apply(lambda x: (x-self.mintest[3])/(self.maxtest[3]-self.mintest[3]))\n",
    "        #print(traindat)\n",
    "        \n",
    "        self.itraindata = traindat.values.tolist()\n",
    "        self.itestdata = testdat.values.tolist()\n",
    "        self.itrainval = np.hstack((np.array(self.itraindata)[:,:4].astype(np.float), np.ones((np.array(self.itraindata)[:,:4].astype(np.float).shape[0], 1), dtype=np.array(self.itraindata)[:,:4].astype(np.float).dtype)))\n",
    "        self.itestval = np.hstack((np.array(self.itestdata)[:,:4].astype(np.float), np.ones((np.array(self.itestdata)[:,:4].astype(np.float).shape[0], 1), dtype=np.array(self.itestdata)[:,:4].astype(np.float).dtype)))\n",
    "        self.exotrain = traindat.iloc[:,-1]\n",
    "        self.exotest = testdat.iloc[:,-1]\n",
    "        self.aexotrain = [] #expected train set output encoded\n",
    "        self.aexotest = [] #expected test set output encoded\n",
    "        self.error = 1\n",
    "        \n",
    "        for i,k in enumerate(self.exotrain):\n",
    "            if(self.exotrain[i] == \"Iris-setosa\"): #harus diubah biar bisa dinamis\n",
    "                self.aexotrain.append([1,0,0])\n",
    "            elif(self.exotrain[i] == \"Iris-versicolor\"):\n",
    "                self.aexotrain.append([0,1,0])\n",
    "            elif(self.exotrain[i] == \"Iris-virginica\"):\n",
    "                self.aexotrain.append([0,0,1])\n",
    "                \n",
    "        for i,k in enumerate(self.exotest):\n",
    "            if(self.exotest[i] == \"Iris-setosa\"): #harus diubah biar bisa dinamis\n",
    "                self.aexotest.append([1,0,0])\n",
    "            elif(self.exotest[i] == \"Iris-versicolor\"):\n",
    "                self.aexotest.append([0,1,0])\n",
    "            elif(self.exotest[i] == \"Iris-virginica\"):\n",
    "                self.aexotest.append([0,0,1])\n",
    "    \n",
    "    def norm(self,data,min,max):\n",
    "        return 2\n",
    "        \n",
    "    def sig(self,x):\n",
    "        return 1 /(1+(math.e**-x))\n",
    "    \n",
    "    def mse(self,a,tar):\n",
    "        etot = 0\n",
    "        for i,k in enumerate(tar):\n",
    "            etot+=(np.linalg.norm(tar[i]-a[i]))**2\n",
    "        return etot/(2*(len(tar)-1))\n",
    "        \n",
    "        \n",
    "    def info(self):\n",
    "        print('Number of node of input layer: ',self.nodei)\n",
    "        print('Number of node of hidden layer: ',self.nodeh)\n",
    "        print('Number of node of output layer: ',self.nodeo)\n",
    "        print('Learning rate: ',self.a)\n",
    "        print('Initial weight input-hidden:',self.w1)\n",
    "        print('Initial weight hidden-output:',self.w2)\n",
    "        \n",
    "    def viewdata(self):\n",
    "        #print('dataset: ')\n",
    "        #print(self.itrainval)\n",
    "        #print(self.aexotrain)\n",
    "        #print(self.exotrain[0])\n",
    "        print(self.maxtrain)\n",
    "        #self.itraindata[0] = self.norm(self.itraindata[0],1,2)\n",
    "        #print(self.itraindata)\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        preval = 100 #previous error\n",
    "        while self.error > self.errort:\n",
    "            #print('#Feed forward')\n",
    "            #print('Net node array before sigmoid:')\n",
    "            self.neth = np.matmul(self.itrainval,self.w1)\n",
    "            #print(self.neth)\n",
    "            self.h = self.sig(self.neth)\n",
    "            #print('Net node array after sigmoid:')\n",
    "            self.h = np.hstack((self.h, np.ones((self.h.shape[0], 1), dtype=self.h.dtype)))\n",
    "            #print(self.h)\n",
    "            #print('W2')\n",
    "            #print(self.w2)\n",
    "            self.neto = np.matmul(self.h,self.w2)\n",
    "            self.o = self.sig(self.neto)\n",
    "            #print(self.o)\n",
    "            #print(len(self.o))\n",
    "            self.error = self.mse(self.o,self.aexotrain)\n",
    "            if(self.error>preval):\n",
    "                print('train stop because error was increased')\n",
    "                break\n",
    "            preval = self.error\n",
    "            print('error: ',self.error)\n",
    "\n",
    "            #print('#Backward pass')\n",
    "            w2t = copy.deepcopy(self.w2)\n",
    "\n",
    "            for i,ii in enumerate(self.w2): #for the output-hidden weights\n",
    "\n",
    "                if(i<(len(self.w2)-1)):\n",
    "                    for j,jj in enumerate(self.w2[i]): #for the weight\n",
    "                        delta = 0\n",
    "                        for k,kk in enumerate(self.o):\n",
    "                            delta += (self.o[k][j]-self.aexotrain[k][j])*(1-self.o[k][j])*self.o[k][j]*self.h[k][i]#tweak\n",
    "                        delta = delta/len(self.o)\n",
    "                        self.w2[i][j] = w2t[i][j]-(self.a*delta)\n",
    "                else:\n",
    "                    for j,jj in enumerate(self.w2[i]): #for bias\n",
    "                        delta = 0\n",
    "                        for k,kk in enumerate(self.o):\n",
    "                            delta += (self.o[k][j]-self.aexotrain[k][j])*(1-self.o[k][j])*self.o[k][j]\n",
    "                        delta = delta/len(self.o)\n",
    "                        self.w2[i][j] = w2t[i][j]-(self.a*delta)\n",
    "\n",
    "            for i,ii in enumerate(self.w1): #for the hidden-input weights\n",
    "                if(i<(len(self.w1)-1)):\n",
    "                    for j,jj in enumerate(self.w1[i]):\n",
    "                        delta = 0\n",
    "                        for k,kk in enumerate(self.h):\n",
    "                            eouth = 0\n",
    "                            for n,m in enumerate(self.o[k]):\n",
    "                                eouth += (self.o[k][n]-self.aexotrain[k][n])*(1-self.o[k][n])*self.o[k][n]*w2t[j][n]#tweak\n",
    "                            delta += eouth*self.h[k][i]*(1-self.h[k][i])*self.itrainval[k][i]\n",
    "                        delta = delta/len(self.h)\n",
    "                        self.w1[i][j] = self.w1[i][j]-(delta*self.a)\n",
    "                else:\n",
    "                    for j,jj in enumerate(self.w1[i]):\n",
    "                        delta = 0\n",
    "                        for k,kk in enumerate(self.h):\n",
    "                            eouth = 0\n",
    "                            for n,m in enumerate(self.o[k]):\n",
    "                                eouth += (self.o[k][n]-self.aexotrain[k][n])*(1-self.o[k][n])*self.o[k][n]#tweak\n",
    "                            delta += eouth*self.h[k][i]*(1-self.h[k][i])*self.itrainval[k][i]\n",
    "                        delta = delta/len(self.h)\n",
    "                        self.w1[i][j] = self.w1[i][j]-(delta*self.a)\n",
    "    def test(self):\n",
    "        self.neth = np.matmul(self.itestval,self.w1)\n",
    "        self.h = self.sig(self.neth)\n",
    "        self.h = np.hstack((self.h, np.ones((self.h.shape[0], 1), dtype=self.h.dtype)))\n",
    "        self.neto = np.matmul(self.h,self.w2)\n",
    "        self.o = self.sig(self.neto)\n",
    "        salah = 0\n",
    "        for i,ii in enumerate(self.o):\n",
    "            if(np.array(self.o[i]).argmax()!=np.array(self.aexotest[i]).argmax()):\n",
    "                salah+=1\n",
    "        benar = len(self.o)-salah\n",
    "        print('salah: ',salah)\n",
    "        print('benar: ',benar)\n",
    "        print('akurasi: ',benar/len(self.o))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"./datasets/iris.csv\"\n",
    "testdata = \"./datasets/test.csv\"\n",
    "inputnode = 4\n",
    "hiddennode = 5\n",
    "outputnode = 3\n",
    "learningrate = 0.1\n",
    "tolerableerror = 0.01\n",
    "neural = NeuralNetwork(inputnode,hiddennode,outputnode,learningrate,dataset,testdata,0.35,0.6,tolerableerror)\n",
    "#neural.info()\n",
    "#neural.viewdata()\n",
    "neural.train()\n",
    "neural.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
