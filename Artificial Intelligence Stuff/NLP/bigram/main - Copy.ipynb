{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('.', '['), 1939), ((',', 'dan'), 1526), ((')', ','), 838), ((')', '.'), 623), ((',', 'yang'), 521), (('--', '--'), 364), (('--', '-Judul'), 359), (('-Judul', ':'), 359), (('1', ']'), 341), (('pada', 'tahun'), 341), (('[', '1'), 340), (('.', 'Pada'), 300), (('.', 'Di'), 279), (('itu', ','), 268), (('berasal', 'dari'), 255), ((',', 'atau'), 255), (('salah', 'satu'), 240), ((')', 'dan'), 226), ((',', 'yaitu'), 226), ((']', '['), 225), ((',', 'dengan'), 220), (('.', 'Dalam'), 203), (('ini', ','), 203), (('yang', 'lebih'), 201), ((',', 'namun'), 198), ((',', 'di'), 198), ((',', 'seperti'), 195), (('2', ']'), 188), (('[', '2'), 187), (('3', ']'), 182), (('[', '3'), 181), (('digunakan', 'untuk'), 179), (('[', '4'), 167), (('4', ']'), 167), ((')', 'yang'), 164), (('di', 'Indonesia'), 164), (('yang', 'paling'), 162), (('terdiri', 'dari'), 162), (('di', 'dalam'), 159), (('yang', 'tidak'), 152), ((',', '['), 151), (('di', 'dunia'), 150), ((',', 'serta'), 143), ((',', 'sehingga'), 143), ((')', 'adalah'), 139), (('di', 'atas'), 137), (('yang', 'dapat'), 133), (('yang', 'disebut'), 131), (('.', 'Namun'), 131), (('.', 'Selain'), 129), (('Amerika', 'Serikat'), 129), ((',', 'maka'), 127), ((',', 'tetapi'), 126), (('yang', 'sangat'), 126), (('.', 'Beberapa'), 125), (('digunakan', 'sebagai'), 121), (('[', '5'), 118), (('5', ']'), 118), ((']', 'Pada'), 118), ((',', 'karena'), 113), (('di', 'bawah'), 113), (('dikenal', 'sebagai'), 110), (('ke', 'dalam'), 110), (('yang', 'memiliki'), 109), (('ini', 'adalah'), 106), (('lebih', 'dari'), 106), (('saat', 'ini'), 106), (('berada', 'di'), 104), (('Indonesia', ','), 104), ((\"''\", '.'), 103), (('saat', 'itu'), 103), (('Selain', 'itu'), 102), (('dalam', 'bahasa'), 101), (('yang', 'telah'), 101), (('antara', 'lain'), 100), (('Pada', 'tahun'), 99), (('.', 'Buah'), 98), (('di', 'mana'), 97), ((',', 'sedangkan'), 97), (('yang', 'sama'), 96), (('pada', 'saat'), 96), ((\"''\", ','), 96), (('[', '7'), 95), (('7', ']'), 95), (('pada', 'masa'), 95), (('di', 'daerah'), 93), (('.', ')'), 93), ((',', 'terutama'), 92), (('.', 'Setelah'), 92), (('tersebut', '.'), 91), (('Hal', 'ini'), 89), (('dikenal', 'dengan'), 89), ((')', ';'), 88), (('[', '6'), 88), (('6', ']'), 88), (('yang', 'digunakan'), 88), (('ini', 'juga'), 87), (('.', 'Hal'), 87), ((',', 'termasuk'), 84), (('di', 'London'), 84)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import math\n",
    "#from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "#nltk.download('punkt')\n",
    "def find_ngrams(input_list, n):\n",
    "    return zip(*[input_list[i:] for i in range(n)])\n",
    "#sdef perplex():\n",
    "    \n",
    "with open('wikipedia.txt', 'r', encoding='utf-8') as myfile:\n",
    "    data=myfile.read().replace('\\n', '')\n",
    "    \n",
    "words = nltk.word_tokenize(data)\n",
    "#print(words)\n",
    "\n",
    "bigrams = find_ngrams(words, 2)\n",
    "#bigrams = ngrams(words,2)\n",
    "#print(list(bigram))\n",
    "\n",
    "\n",
    "# model = nltk.FreqDist(bigrams)\n",
    "# for k,v in model.items():\n",
    "#     if(k[0]==\"adalah\"):\n",
    "#         print(k,v)\n",
    "    \n",
    "model = Counter(bigrams)\n",
    "print(model.most_common(100))\n",
    "\n",
    "\n",
    "#my_bigrams = nltk.bigrams(words)\n",
    "#print(type( my_bigrams))\n",
    "#my_trigrams = nltk.trigrams(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict the next word after word: dengan\n",
      "\n",
      "predicted word after word \"dengan\" is \"nama\"\n"
     ]
    }
   ],
   "source": [
    "#print(type(bigrams))\n",
    "#print(model.keys() )\n",
    "#model['adalah']\n",
    "already = 0\n",
    "wword = input('predict the next word after word: ')\n",
    "predicted_word = ''\n",
    "pword_counter = 0\n",
    "for k,v in model.most_common():\n",
    "    if(k[0]==wword):\n",
    "        pword_counter += 1\n",
    "for k,v in model.most_common():\n",
    "    if(k[0]==wword):\n",
    "        if(already==0):\n",
    "            already=1\n",
    "            predicted_word=k[1]\n",
    "        #print(k,\"with probability:\",v/pword_counter)\n",
    "print('')\n",
    "print('predicted word after word \"'+wword+'\" is \"'+predicted_word+'\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence to be analyzed: di Indonesia terdapat tempat yang sangat\n",
      "['di', 'Indonesia', 'terdapat', 'tempat', 'yang', 'sangat']\n",
      "di Indonesia\n",
      "('di', 'Indonesia') 164\n",
      "Indonesia terdapat\n",
      "('Indonesia', 'terdapat') 4\n",
      "terdapat tempat\n",
      "('terdapat', 'tempat') 1\n",
      "tempat yang\n",
      "('tempat', 'yang') 19\n",
      "yang sangat\n",
      "('yang', 'sangat') 126\n",
      "2.951738484487039e-07\n",
      "perplexity is:  12.255198605178915\n"
     ]
    }
   ],
   "source": [
    "sentence = input('Enter a sentence to be analyzed: ')\n",
    "sentence_map = nltk.word_tokenize(sentence)\n",
    "print(sentence_map)\n",
    "#print(len(sentence_map))\n",
    " #first word counter\n",
    "i=0\n",
    "prob=1\n",
    "while i<len(sentence_map)-1:\n",
    "    print(sentence_map[i],sentence_map[i+1])\n",
    "    fwordc=0\n",
    "    for k,v in model.most_common():\n",
    "        if(k[0]==sentence_map[i]):\n",
    "            fwordc += 1\n",
    "    for k,v in model.most_common():\n",
    "        if(k[0]==sentence_map[i] and k[1]==sentence_map[i+1]):\n",
    "            prob *= v/fwordc\n",
    "            print(k,v)\n",
    "    i+=1\n",
    "print(prob)\n",
    "perplexity = (1/prob)**(1/len(sentence_map))\n",
    "print('perplexity is: ',perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
